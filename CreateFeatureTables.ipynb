{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# This should be roughly the content of the first code cell\n",
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(1337)\n",
    "random.seed(1337)\n",
    "\n",
    "# Plotting support\n",
    "from matplotlib import pyplot as plt\n",
    "# from plotnine import\n",
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "from skimage import io\n",
    "import cv2\n",
    "from scipy import stats\n",
    "from skimage.util import compare_images\n",
    "from PIL import Image\n",
    "from skimage.metrics import mean_squared_error, structural_similarity, hausdorff_distance, normalized_root_mse, peak_signal_noise_ratio\n",
    "plt.rc('image', cmap='gray')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "genuine_processed = np.load('training/genuine_processed.npy')\n",
    "forged_processed = np.load('training/forged_processed.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "genuine_labels = np.load('training/genuine_labels.npy')\n",
    "forged_labels = np.load('training/forged_labels.npy')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "reference_signatures = np.unique(genuine_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_comparison_metrics(image1, image2):\n",
    "    mse = Simage1, image2)\n",
    "    ssim = structural_similarity(image1, image2, data_range=1)\n",
    "    log_and = np.sum(np.logical_and(image1, image2))\n",
    "    simple_diff = np.sum(np.abs(image1-image2))\n",
    "\n",
    "    checkerboard = compare_images(image1, image2, method='checkerboard')\n",
    "    blend = compare_images(image1, image2, method='blend')\n",
    "    checkerboard_mean = np.mean(checkerboard)\n",
    "    blend_mean = np.mean(blend)\n",
    "\n",
    "    hd = hausdorff_distance(image1, image2)\n",
    "    nrmse = normalized_root_mse(image1, image2)\n",
    "\n",
    "    psnr = peak_signal_noise_ratio(image1, image2)\n",
    "\n",
    "    return [mse, ssim, log_and, simple_diff, checkerboard_mean, blend_mean, hd, nrmse, psnr]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#[mse, ssim, log_and, simple_diff, checkerboard_mean, blend_mean, hd, nrmse, psnr]\n",
    "feature_table = []\n",
    "\n",
    "curr_genuine = genuine_processed[genuine_labels == 1]\n",
    "curr_forged = forged_processed[forged_labels ==1 ]\n",
    "\n",
    "for i in range(len(curr_genuine)):\n",
    "    for j in range(i+1, len(curr_genuine)):\n",
    "        row = ['label1_gen'+str(i) + '_gen'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_genuine[j]))\n",
    "        row.append(True)\n",
    "        feature_table.append(np.array(row))\n",
    "\n",
    "    for j in range(len(curr_forged)):\n",
    "        row = ['label1_gen'+str(i) + '_for'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_forged[j]))\n",
    "        row.append(False)\n",
    "        feature_table.append(np.array(row))\n",
    "\n",
    "feature_table = np.array(feature_table)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----138.74----\n",
      "label 1 done\n",
      "----274.43----\n",
      "label 2 done\n",
      "----532.03----\n",
      "label 3 done\n",
      "----691.76----\n",
      "label 4 done\n",
      "----894.38----\n",
      "label 6 done\n",
      "----1103.95----\n",
      "label 9 done\n",
      "----2322.21----\n",
      "label 12 done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "full_feature_table = []\n",
    "st=time.time()\n",
    "for label in reference_signatures:\n",
    "    curr_genuine = genuine_processed[genuine_labels == label]\n",
    "    curr_forged = forged_processed[forged_labels ==label ]\n",
    "\n",
    "    for i in range(len(curr_genuine)):\n",
    "        for j in range(i+1, len(curr_genuine)):\n",
    "            row = ['label'+str(label)+'_gen'+str(i) + '_gen'+str(j)]\n",
    "            row.extend( get_comparison_metrics(curr_genuine[i], curr_genuine[j]))\n",
    "            row.append(True)\n",
    "            full_feature_table.append(np.array(row))\n",
    "\n",
    "        for j in range(len(curr_forged)):\n",
    "            row = ['label'+str(label)+'_gen'+str(i) + '_for'+str(j)]\n",
    "            row.extend( get_comparison_metrics(curr_genuine[i], curr_forged[j]))\n",
    "            row.append(False)\n",
    "            full_feature_table.append(np.array(row))\n",
    "    print(\"----%.2f----\"%(time.time()-st))\n",
    "    print('label', label, 'done')\n",
    "full_feature_table = np.array(feature_table)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.save('training/feature_table.npy', full_feature_table)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "----207.79----\n",
      "label 1 done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_table1 = []\n",
    "st=time.time()\n",
    "print('starting')\n",
    "label = 1\n",
    "\n",
    "curr_genuine = genuine_processed[genuine_labels == label]\n",
    "curr_forged = forged_processed[forged_labels ==label ]\n",
    "\n",
    "for i in range(len(curr_genuine)):\n",
    "    for j in range(i+1, len(curr_genuine)):\n",
    "        row = ['label'+str(label)+'_gen'+str(i) + '_gen'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_genuine[j]))\n",
    "        row.append(1)\n",
    "        feature_table1.append(np.array(row))\n",
    "\n",
    "    for j in range(len(curr_forged)):\n",
    "        row = ['label'+str(label)+'_gen'+str(i) + '_for'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_forged[j]))\n",
    "        row.append(0)\n",
    "        feature_table1.append(np.array(row))\n",
    "print(\"----%.2f----\"%(time.time()-st))\n",
    "print('label', label, 'done')\n",
    "feature_table1 = np.array(feature_table1)\n",
    "\n",
    "np.save('training/feature_table1.npy', feature_table1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "----225.23----\n",
      "label 2 done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_table2 = []\n",
    "st=time.time()\n",
    "print('starting')\n",
    "label = 2\n",
    "\n",
    "curr_genuine = genuine_processed[genuine_labels == label]\n",
    "curr_forged = forged_processed[forged_labels ==label ]\n",
    "\n",
    "for i in range(len(curr_genuine)):\n",
    "    for j in range(i+1, len(curr_genuine)):\n",
    "        row = ['label'+str(label)+'_gen'+str(i) + '_gen'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_genuine[j]))\n",
    "        row.append(True)\n",
    "        feature_table2.append(np.array(row))\n",
    "\n",
    "    for j in range(len(curr_forged)):\n",
    "        row = ['label'+str(label)+'_gen'+str(i) + '_for'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_forged[j]))\n",
    "        row.append(False)\n",
    "        feature_table2.append(np.array(row))\n",
    "print(\"----%.2f----\"%(time.time()-st))\n",
    "print('label', label, 'done')\n",
    "feature_table2 = np.array(feature_table2)\n",
    "\n",
    "np.save('training/feature_table2.npy', feature_table2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "----250.90----\n",
      "label 3 done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_table3 = []\n",
    "st=time.time()\n",
    "print('starting')\n",
    "label = 3\n",
    "\n",
    "curr_genuine = genuine_processed[genuine_labels == label]\n",
    "curr_forged = forged_processed[forged_labels ==label ]\n",
    "\n",
    "for i in range(len(curr_genuine)):\n",
    "    for j in range(i+1, len(curr_genuine)):\n",
    "        row = ['label'+str(label)+'_gen'+str(i) + '_gen'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_genuine[j]))\n",
    "        row.append(True)\n",
    "        feature_table3.append(np.array(row))\n",
    "\n",
    "    for j in range(len(curr_forged)):\n",
    "        row = ['label'+str(label)+'_gen'+str(i) + '_for'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_forged[j]))\n",
    "        row.append(False)\n",
    "        feature_table3.append(np.array(row))\n",
    "print(\"----%.2f----\"%(time.time()-st))\n",
    "print('label', label, 'done')\n",
    "feature_table3 = np.array(feature_table3)\n",
    "\n",
    "np.save('training/feature_table3.npy', feature_table3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "----189.51----\n",
      "label 4 done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_table4 = []\n",
    "st=time.time()\n",
    "print('starting')\n",
    "label = 4\n",
    "\n",
    "curr_genuine = genuine_processed[genuine_labels == label]\n",
    "curr_forged = forged_processed[forged_labels ==label ]\n",
    "\n",
    "for i in range(len(curr_genuine)):\n",
    "    for j in range(i+1, len(curr_genuine)):\n",
    "        row = ['label'+str(label)+'_gen'+str(i) + '_gen'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_genuine[j]))\n",
    "        row.append(True)\n",
    "        feature_table4.append(np.array(row))\n",
    "\n",
    "    for j in range(len(curr_forged)):\n",
    "        row = ['label'+str(label)+'_gen'+str(i) + '_for'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_forged[j]))\n",
    "        row.append(False)\n",
    "        feature_table4.append(np.array(row))\n",
    "print(\"----%.2f----\"%(time.time()-st))\n",
    "print('label', label, 'done')\n",
    "feature_table4 = np.array(feature_table4)\n",
    "\n",
    "np.save('training/feature_table4.npy', feature_table4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "----222.19----\n",
      "label 6 done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_table6 = []\n",
    "st=time.time()\n",
    "print('starting')\n",
    "label = 6\n",
    "\n",
    "curr_genuine = genuine_processed[genuine_labels == label]\n",
    "curr_forged = forged_processed[forged_labels ==label ]\n",
    "\n",
    "for i in range(len(curr_genuine)):\n",
    "    for j in range(i+1, len(curr_genuine)):\n",
    "        row = ['label'+str(label)+'_gen'+str(i) + '_gen'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_genuine[j]))\n",
    "        row.append(True)\n",
    "        feature_table6.append(np.array(row))\n",
    "\n",
    "    for j in range(len(curr_forged)):\n",
    "        row = ['label'+str(label)+'_gen'+str(i) + '_for'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_forged[j]))\n",
    "        row.append(False)\n",
    "        feature_table6.append(np.array(row))\n",
    "print(\"----%.2f----\"%(time.time()-st))\n",
    "print('label', label, 'done')\n",
    "feature_table6 = np.array(feature_table6)\n",
    "\n",
    "np.save('training/feature_table6.npy', feature_table6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "----226.22----\n",
      "label 9 done\n"
     ]
    }
   ],
   "source": [
    "feature_table9 = []\n",
    "st=time.time()\n",
    "print('starting')\n",
    "label = 9\n",
    "\n",
    "curr_genuine = genuine_processed[genuine_labels == label]\n",
    "curr_forged = forged_processed[forged_labels ==label ]\n",
    "\n",
    "for i in range(len(curr_genuine)):\n",
    "    for j in range(i+1, len(curr_genuine)):\n",
    "        row = ['label'+str(label)+'_gen'+str(i) + '_gen'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_genuine[j]))\n",
    "        row.append(True)\n",
    "        feature_table9.append(np.array(row))\n",
    "\n",
    "    for j in range(len(curr_forged)):\n",
    "        row = ['label'+str(label)+'_gen'+str(i) + '_for'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_forged[j]))\n",
    "        row.append(False)\n",
    "        feature_table9.append(np.array(row))\n",
    "print(\"----%.2f----\"%(time.time()-st))\n",
    "print('label', label, 'done')\n",
    "feature_table9 = np.array(feature_table9)\n",
    "\n",
    "np.save('training/feature_table9.npy', feature_table9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "----167.89----\n",
      "label 12 done\n"
     ]
    }
   ],
   "source": [
    "feature_table12 = []\n",
    "st=time.time()\n",
    "print('starting')\n",
    "label = 12\n",
    "\n",
    "curr_genuine = genuine_processed[genuine_labels == label]\n",
    "curr_forged = forged_processed[forged_labels ==label ]\n",
    "\n",
    "for i in range(len(curr_genuine)):\n",
    "    for j in range(i+1, len(curr_genuine)):\n",
    "        row = ['label'+str(label)+'_gen'+str(i) + '_gen'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_genuine[j]))\n",
    "        row.append(True)\n",
    "        feature_table12.append(np.array(row))\n",
    "\n",
    "    for j in range(len(curr_forged)):\n",
    "        row = ['label'+str(label)+'_gen'+str(i) + '_for'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_forged[j]))\n",
    "        row.append(False)\n",
    "        feature_table12.append(np.array(row))\n",
    "print(\"----%.2f----\"%(time.time()-st))\n",
    "print('label', label, 'done')\n",
    "feature_table12 = np.array(feature_table12)\n",
    "\n",
    "np.save('training/feature_table12.npy', feature_table12)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "----217.92----\n",
      "label 14 done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_table14 = []\n",
    "st=time.time()\n",
    "print('starting')\n",
    "label = 14\n",
    "\n",
    "curr_genuine = genuine_processed[genuine_labels == label]\n",
    "curr_forged = forged_processed[forged_labels ==label ]\n",
    "\n",
    "for i in range(len(curr_genuine)):\n",
    "    for j in range(i+1, len(curr_genuine)):\n",
    "        row = ['label'+str(label)+'_gen'+str(i) + '_gen'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_genuine[j]))\n",
    "        row.append(True)\n",
    "        feature_table14.append(np.array(row))\n",
    "\n",
    "    for j in range(len(curr_forged)):\n",
    "        row = ['label'+str(label)+'_gen'+str(i) + '_for'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_forged[j]))\n",
    "        row.append(False)\n",
    "        feature_table14.append(np.array(row))\n",
    "print(\"----%.2f----\"%(time.time()-st))\n",
    "print('label', label, 'done')\n",
    "feature_table14 = np.array(feature_table14)\n",
    "\n",
    "np.save('training/feature_table14.npy', feature_table14)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "----224.12----\n",
      "label 15 done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_table15 = []\n",
    "st=time.time()\n",
    "print('starting')\n",
    "label = 15\n",
    "\n",
    "curr_genuine = genuine_processed[genuine_labels == label]\n",
    "curr_forged = forged_processed[forged_labels ==label ]\n",
    "\n",
    "for i in range(len(curr_genuine)):\n",
    "    for j in range(i+1, len(curr_genuine)):\n",
    "        row = ['label'+str(label)+'_gen'+str(i) + '_gen'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_genuine[j]))\n",
    "        row.append(True)\n",
    "        feature_table15.append(np.array(row))\n",
    "\n",
    "    for j in range(len(curr_forged)):\n",
    "        row = ['label'+str(label)+'_gen'+str(i) + '_for'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_forged[j]))\n",
    "        row.append(False)\n",
    "        feature_table15.append(np.array(row))\n",
    "print(\"----%.2f----\"%(time.time()-st))\n",
    "print('label', label, 'done')\n",
    "feature_table15 = np.array(feature_table15)\n",
    "\n",
    "np.save('training/feature_table15.npy', feature_table15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "----206.85----\n",
      "label 16 done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_table16 = []\n",
    "st=time.time()\n",
    "print('starting')\n",
    "label = 16\n",
    "\n",
    "curr_genuine = genuine_processed[genuine_labels == label]\n",
    "curr_forged = forged_processed[forged_labels ==label ]\n",
    "\n",
    "for i in range(len(curr_genuine)):\n",
    "    for j in range(i+1, len(curr_genuine)):\n",
    "        row = ['label'+str(label)+'_gen'+str(i) + '_gen'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_genuine[j]))\n",
    "        row.append(True)\n",
    "        feature_table16.append(np.array(row))\n",
    "\n",
    "    for j in range(len(curr_forged)):\n",
    "        row = ['label'+str(label)+'_gen'+str(i) + '_for'+str(j)]\n",
    "        row.extend( get_comparison_metrics(curr_genuine[i], curr_forged[j]))\n",
    "        row.append(False)\n",
    "        feature_table16.append(np.array(row))\n",
    "print(\"----%.2f----\"%(time.time()-st))\n",
    "print('label', label, 'done')\n",
    "feature_table16 = np.array(feature_table16)\n",
    "\n",
    "np.save('training/feature_table16.npy', feature_table16)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}